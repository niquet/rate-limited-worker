# Rate Limited Worker

- 

## Components

**OpenTelemetry**

- OpenTelemetry is made up of several main components (some are omitted below):
    - Specification
    - Collector
    - Instrumentation
    - Expoerter
    - Sampler
- The **specification** describes requirements and expectations for all implementations
- It defines the following:
    - API: Defines data types and operations for generating and correlating tracing, metrics, and logging data
    - SDK: Defines requirements for a language-specific implementation of the API, as well as configuration, data processing, and exporting concepts
    - Data: Defines the OpenTelemetry Protocol (OTLP) and vendor-agnostic semantic conventions that a telemetry backend can provide support for
- **Exporters** send telemetry to the OpenTelemetry Collector to make sure it’s exported correctly
- Using the Collector in production environments is a best practice
- To visualize your telemetry, export it to a backend such as Jaeger, Zipkin, Prometheus, or a vendor-specific backend
- OpenTelemetry Protocol (OTLP) exporters are designed with the OpenTelemetry data model in mind, emitting OTel data without any loss of information
- Sampling is a process that restricts the amount of traces that are generated by a system
- Each language-specific implementation of OpenTelemetry offers several head samplers

**OpenTelemetry Collector**

- The OpenTelemetry Collector receives traces, metrics, and logs, processes the telemetry, and exports it to a wide variety of observability backends using its components
- It supports receiving telemetry data in multiple formats (for example, OTLP, Jaeger, Prometheus, as well as many commercial/proprietary tools) and sending data to one or more backends
- It also supports processing and filtering telemetry data before it gets exported
- It is recommended to use a collector alongside your service, since it allows your service to offload data quickly and the collector can take care of additional handling like retries, batching, encryption or even sensitive data filtering
- The default OTLP exporters in each language assume a local collector endpoint, so if you launch a collector it will automatically start receiving telemetry
- You can install the OpenTelemetry Collector by adding it to your existing `compose.yaml` file:

```yaml
otel-collector:
  image: otel/opentelemetry-collector-contrib
  volumes:
    - ./otel-collector-config.yaml:/etc/otelcol-contrib/config.yaml
  ports:
    - 1888:1888 # pprof extension
    - 8888:8888 # Prometheus metrics exposed by the Collector
    - 8889:8889 # Prometheus exporter metrics
    - 13133:13133 # health_check extension
    - 4317:4317 # OTLP gRPC receiver
    - 4318:4318 # OTLP http receiver
    - 55679:55679 # zpages extension
```

- The `agent collector deployment pattern` consists of applications — instrumented with an OpenTelemetry SDK using OpenTelemetry protocol (OTLP) — or other collectors (using the OTLP exporter) that send telemetry signals to a collector instance running with the application or on the same host as the application (such as a sidecar or a daemonset)
    - In the app, the SDK is configured to send OTLP data to a collector (each client-side SDK or downstream collector is configured with a collector location)
    - The collector is configured to send telemetry data to one or more backends
- Example of the `agent collector deployment pattern`:
    - You manually instrument, a Go application to export metrics using the OpenTelemetry Go SDK
    - You would set the `OTEL_METRICS_EXPORTER` to otlp (which is the default value) and configure the OTLP exporter with the address of your collector (`export OTEL_EXPORTER_OTLP_ENDPOINT=http://collector.example.com:4318`)
- A collector serving at `collector.example.com:4318` would then be configured like so:

```yaml
# Traces
receivers:
  otlp: # the OTLP receiver the app is sending traces to
    protocols:
      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:

exporters:
  otlp/jaeger: # Jaeger supports OTLP directly
    endpoint: https://jaeger.example.com:4317

service:
  pipelines:
    traces/dev:
      receivers: [otlp]
      processors: [batch]
      exporters: [otlp/jaeger]
```

```yaml
# Metrics
receivers:
  otlp: # the OTLP receiver the app is sending metrics to
    protocols:
      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:

exporters:
  prometheusremotewrite: # the PRW exporter, to ingest metrics to backend
    endpoint: https://prw.example.com/v1/api/remote_write

service:
  pipelines:
    metrics/prod:
      receivers: [otlp]
      processors: [batch]
      exporters: [prometheusremotewrite]
```

```yaml
# Logs
receivers:
  otlp: # the OTLP receiver the app is sending logs to
    protocols:
      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:

exporters:
  file: # the File Exporter, to ingest logs to local file
    path: ./app42_example.log
    rotation:

service:
  pipelines:
    logs/dev:
      receivers: [otlp]
      processors: [batch]
      exporters: [file]
```

- You can configure the OpenTelemetry Collector to suit your observability needs
- By default, the Collector configuration is located in `/etc/<otel-directory>/config.yaml`, where `<otel-directory>` can be `otelcol`, `otelcol-contrib`, or another value, depending on the Collector version or the Collector distribution you’re using
- To validate a configuration file, use the validate command: `otelcol validate --config=customconfig.yaml`
- The structure of any Collector configuration file consists of four classes of pipeline components that access telemetry data:
    - Receivers
    - Processors
    - Exporters
    - Connectors
- After each pipeline component is configured you must enable it using the pipelines within the service section of the configuration file
- Besides pipeline components you can also configure extensions, which provide capabilities that can be added to the Collector, such as diagnostic tools
- Extensions don’t require direct access to telemetry data and are enabled through the service section
- It is generally preferable to bind endpoints to `localhost` when all clients are local
- The Collector currently defaults to `0.0.0.0`, but the default will be changed to `localhost`
- Note that receivers, processors, exporters and pipelines are defined through component identifiers following the `type[/name]` format

Receivers

- Receivers collect telemetry from one or more sources
- They can be pull or push based, and may support one or more data sources
- Receivers are configured in the receivers section
- Many receivers come with default settings, so that specifying the name of the receiver is enough to configure it
- If you need to configure a receiver or want to change the default configuration, you can do so in this section
- Any setting you specify overrides the default values, if present
- Configuring a receiver does not enable it
- Receivers are enabled by adding them to the appropriate pipelines within the service section
- The Collector requires one or more receivers
- The following example shows various receivers in the same configuration file:

```yaml
receivers:
  # Data sources: logs
  fluentforward:
    endpoint: 0.0.0.0:8006

  # Data sources: metrics
  hostmetrics:
    scrapers:
      cpu:
      disk:
      filesystem:
      load:
      memory:
      network:
      process:
      processes:
      paging:

  # Data sources: traces
  jaeger:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      thrift_binary:
      thrift_compact:
      thrift_http:

  # Data sources: traces, metrics, logs
  kafka:
    protocol_version: 2.0.0

  # Data sources: traces, metrics
  opencensus:

  # Data sources: traces, metrics, logs
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
        tls:
          cert_file: cert.pem
          key_file: cert-key.pem
      http:
        endpoint: 0.0.0.0:4318

  # Data sources: metrics
  prometheus:
    config:
      scrape_configs:
        - job_name: otel-collector
          scrape_interval: 5s
          static_configs:
            - targets: [localhost:8888]

  # Data sources: traces
  zipkin:

```

- More at [https://github.com/open-telemetry/opentelemetry-collector/blob/main/receiver/README.md](https://github.com/open-telemetry/opentelemetry-collector/blob/main/receiver/README.md)

Processors

- Processors take the data collected by receivers and modify or transform it before sending it to the exporters
- Data processing happens according to rules or settings defined for each processor, which might include filtering, dropping, renaming, or recalculating telemetry, among other operations
- The order of the processors in a pipeline determines the order of the processing operations that the Collector applies to the signal
- Processors are optional, although some are recommended
- You can configure processors using the processors section of the Collector configuration file
- Any setting you specify overrides the default values, if present
- Configuring a processor does not enable it
- Processors are enabled by adding them to the appropriate pipelines within the service section
- The following example shows several default processors in the same configuration file:

```yaml
processors:
  # Data sources: traces
  attributes:
    actions:
      - key: environment
        value: production
        action: insert
      - key: db.statement
        action: delete
      - key: email
        action: hash

  # Data sources: traces, metrics, logs
  batch:

  # Data sources: metrics, metrics, logs
  filter:
    error_mode: ignore
    traces:
      span:
        - 'attributes["container.name"] == "app_container_1"'
        - 'resource.attributes["host.name"] == "localhost"'
        - 'name == "app_3"'
      spanevent:
        - 'attributes["grpc"] == true'
        - 'IsMatch(name, ".*grpc.*")'
    metrics:
      metric:
        - 'name == "my.metric" and resource.attributes["my_label"] == "abc123"'
        - 'type == METRIC_DATA_TYPE_HISTOGRAM'
      datapoint:
        - 'metric.type == METRIC_DATA_TYPE_SUMMARY'
        - 'resource.attributes["service.name"] == "my_service_name"'
    logs:
      log_record:
        - 'IsMatch(body, ".*password.*")'
        - 'severity_number < SEVERITY_NUMBER_WARN'

  # Data sources: traces, metrics, logs
  memory_limiter:
    check_interval: 5s
    limit_mib: 4000
    spike_limit_mib: 500

  # Data sources: traces
  resource:
    attributes:
      - key: cloud.zone
        value: zone-1
        action: upsert
      - key: k8s.cluster.name
        from_attribute: k8s-cluster
        action: insert
      - key: redundant-attribute
        action: delete

  # Data sources: traces
  probabilistic_sampler:
    hash_seed: 22
    sampling_percentage: 15

  # Data sources: traces
  span:
    name:
      to_attributes:
        rules:
          - ^\/api\/v1\/document\/(?P<documentId>.*)\/update$
      from_attributes: [db.svc, operation]
      separator: '::'

```

- [List of processors](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor)
- [General information on processors](https://github.com/open-telemetry/opentelemetry-collector/tree/main/processor)

Exporters

- Exporters send data to one or more backends or destinations
- Exporters can be pull or push based, and may support one or more data sources
- Each key within the exporters section defines an exporter instance, the key follows the `type/name` format, where type specifies the exporter type (e.g., otlp, kafka, prometheus), and name (optional) can be appended to provide a unique name for multiple instance of the same type
- Most exporters require configuration to specify at least the destination, as well as security settings, like authentication tokens or TLS certificates
- Any setting you specify overrides the default values, if present
- Configuring an exporter does not enable it
- Exporters are enabled by adding them to the appropriate pipelines within the service section
- The Collector requires one or more exporters
- The following example shows various exporters in the same configuration file:

```yaml
exporters:
  # Data sources: traces, metrics, logs
  file:
    path: ./filename.json

  # Data sources: traces
  otlp/jaeger:
    endpoint: jaeger-server:4317
    tls:
      cert_file: cert.pem
      key_file: cert-key.pem

  # Data sources: traces, metrics, logs
  kafka:
    protocol_version: 2.0.0

  # Data sources: traces, metrics, logs
  # NOTE: Prior to v0.86.0 use `logging` instead of `debug`
  debug:
    verbosity: detailed

  # Data sources: traces, metrics
  opencensus:
    endpoint: otelcol2:55678

  # Data sources: traces, metrics, logs
  otlp:
    endpoint: otelcol2:4317
    tls:
      cert_file: cert.pem
      key_file: cert-key.pem

  # Data sources: traces, metrics
  otlphttp:
    endpoint: https://otlp.example.com:4318

  # Data sources: metrics
  prometheus:
    endpoint: 0.0.0.0:8889
    namespace: default

  # Data sources: metrics
  prometheusremotewrite:
    endpoint: http://prometheus.example.com:9411/api/prom/push
    # When using the official Prometheus (running via Docker)
    # endpoint: 'http://prometheus:9090/api/v1/write', add:
    # tls:
    #   insecure: true

  # Data sources: traces
  zipkin:
    endpoint: http://zipkin.example.com:9411/api/v2/spans

```

- [More information on exporter configuration](https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/README.md)

Connectors

- 

Extensions

- 

Service section

- 

Environment variables

- 

Authentication

- 

**OpenTelemetry Collector: Internal Telemetry**

- 

**Troubleshooting**

- 

**Architecture**

- 

## Credits

- [https://opentelemetry.io/docs/collector/quick-start/](https://opentelemetry.io/docs/collector/quick-start/)
- [https://opentelemetry.io/docs/collector/](https://opentelemetry.io/docs/collector/)
- [https://opentelemetry.io/docs/collector/installation/](https://opentelemetry.io/docs/collector/installation/)
- [https://opentelemetry.io/docs/concepts/components/#collector](https://opentelemetry.io/docs/concepts/components/#collector)
- [https://opentelemetry.io/docs/collector/deployment/agent/](https://opentelemetry.io/docs/collector/deployment/agent/)
- [https://opentelemetry.io/docs/collector/configuration/](https://opentelemetry.io/docs/collector/configuration/)
- []()
